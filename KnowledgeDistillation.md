# Knowledge Distillation
> Summary: Learning a (smaller) student model from a (larger) teacher model by using the teacher model's output to data (labelled/unlabelled) as the pseudo labels

## Use in paper

* [Knowledge Distillation](https://arxiv.org/abs/1503.02531)
* [Self-training with Noisy Student improves ImageNet classification](https://arxiv.org/abs/1911.04252)

